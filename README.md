# ğŸ§  Multilingual Topic Drift Detection System

A comprehensive Python-based system that detects, analyzes, and visualizes topic drift in real-time news articles across multiple languages (English, Hindi, Tamil). The system streams live news from NewsAPI, performs advanced NLP preprocessing, applies Latent Dirichlet Allocation (LDA) for topic modeling, detects semantic drift using cosine similarity, and provides interactive visualizations through a Streamlit dashboard.

**Key Features:**
- ğŸ“¡ Real-time news ingestion from NewsAPI
- ğŸŒ Multilingual support (English, Hindi, Tamil)
- ğŸ§® LDA-based topic modeling with 3-5 topics per language
- ğŸ“Š Drift detection using TF-IDF and cosine similarity
- ğŸ“ˆ Interactive Streamlit dashboard with visualizations
- ğŸ’¾ MongoDB for persistent data storage
- ğŸ³ Docker containerization support
- ğŸ¤– PySpark machine learning predictions for drift classification

---

## ğŸ“‹ Table of Contents

- [Architecture Overview](#architecture-overview)
- [System Components](#system-components)
- [Technology Stack](#technology-stack)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Data Flow](#data-flow)
- [APIs & Endpoints](#apis--endpoints)
- [Troubleshooting](#troubleshooting)
- [Future Enhancements](#future-enhancements)

---

## ğŸ—ï¸ Architecture Overview

### System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      TOPIC DRIFT DETECTION SYSTEM               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   NewsAPI Server     â”‚  (External Data Source)
â”‚  - English Articles  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ HTTP GET Request (every 30 sec)
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Real-Time News Ingestion Module        â”‚
â”‚   (newsapi_streaming.py)                 â”‚
â”‚  - Fetch articles every 30 seconds      â”‚
â”‚  - Extract title + description          â”‚
â”‚  - Add timestamp metadata               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Insert Documents
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MongoDB Database                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ documents           â”‚ topics              â”‚ topic_drift_    â”‚ â”‚
â”‚  â”‚ - text              â”‚ - topic_id          â”‚  scores         â”‚ â”‚
â”‚  â”‚ - language          â”‚ - keywords[]        â”‚ - topic_id_1    â”‚ â”‚
â”‚  â”‚ - timestamp         â”‚                     â”‚ - topic_id_2    â”‚ â”‚
â”‚  â”‚ - cleaned_tokens[]  â”‚                     â”‚ - similarity    â”‚ â”‚
â”‚  â”‚                     â”‚                     â”‚ - drift_        â”‚ â”‚
â”‚  â”‚                     â”‚                     â”‚   detected      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ Read & Process                              â”‚ Query Results
      â–¼                                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Preprocessing Pipeline                  â”‚  â”‚   Drift Detection    â”‚
â”‚  (lda_topic_modeling.py)                 â”‚  â”‚  (detect_topic_drift)â”‚
â”‚                                          â”‚  â”‚                      â”‚
â”‚  â€¢ Language detection                    â”‚  â”‚  â€¢ TF-IDF Vectors   â”‚
â”‚  â€¢ Tokenization & normalization         â”‚  â”‚  â€¢ Cosine Similarityâ”‚
â”‚  â€¢ Remove stopwords & punctuation       â”‚  â”‚  â€¢ Threshold: 0.7   â”‚
â”‚  â€¢ Lemmatization                        â”‚  â”‚  â€¢ Timestamp logs   â”‚
â”‚  â€¢ Create Dictionary & Corpus           â”‚  â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                                     â”‚
                   â–¼                                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  LDA Model Training  â”‚          â”‚  Drift Score Calculation â”‚
         â”‚  (Gensim)            â”‚          â”‚                          â”‚
         â”‚  â€¢ 3-5 topics        â”‚          â”‚  â€¢ Compare topic vectors â”‚
         â”‚  â€¢ 10 passes         â”‚          â”‚  â€¢ Store results to DB   â”‚
         â”‚  â€¢ Per language      â”‚          â”‚  â€¢ Track over time       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                                 â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  PySpark ML Pipeline             â”‚
                    â”‚ (predict_topic_drift.py)         â”‚
                    â”‚  â€¢ Load from MongoDB             â”‚
                    â”‚  â€¢ Feature engineering           â”‚
                    â”‚  â€¢ Logistic Regression model     â”‚
                    â”‚  â€¢ Performance metrics (ROC, F1) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Streamlit Dashboard            â”‚
                    â”‚  (dashboard/streamlit_app.py)    â”‚
                    â”‚  ğŸ“Š Document browser             â”‚
                    â”‚  ğŸ“Š Topic keywords               â”‚
                    â”‚  â˜ï¸  WordClouds                  â”‚
                    â”‚  ğŸ“ˆ Similarity charts            â”‚
                    â”‚  ğŸ“‰ Drift trends over time       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ System Components

### 1. **Data Ingestion Layer**
- **newsapi_streaming.py** - Fetches live news articles every 30 seconds
- **real_time_ingestion.py** - Background ingestion with preprocessing

### 2. **Preprocessing & NLP Layer**
- **preprocess_text.py** - Text cleaning and tokenization
- **lda_topic_modeling.py** - Multilingual preprocessing with lemmatization

### 3. **Topic Modeling Layer**
- **Gensim LDA Model** - Generates latent topics per language
- Configurable topics (3-5) with 10 training passes
- Per-language topic models (English, Hindi, Tamil)

### 4. **Drift Detection Layer**
- **detect_topic_drift.py** - Calculates cosine similarity between topics
- TF-IDF vectorization for semantic representation
- Drift threshold: 0.7 (configurable)
- Timestamp logging for trend analysis

### 5. **ML Prediction Layer**
- **predict_topic_drift.py** - PySpark-based drift prediction
- Logistic Regression classification
- Performance metrics: Accuracy, Precision, Recall, F1-Score, ROC-AUC

### 6. **Visualization Layer**
- **Streamlit Dashboard** - Interactive real-time analytics
- Multi-language document browser
- WordCloud visualizations
- Time-series drift trends

---

## ğŸ’» Technology Stack

| Component | Technology | Version |
|-----------|-----------|---------|
| **Language** | Python | 3.10.x |
| **Data Collection** | NewsAPI, Requests | - |
| **NLP Framework** | SpaCy, NLTK | 3.8.5, 3.9.1 |
| **Topic Modeling** | Gensim | 4.3.3 |
| **ML Framework** | PySpark, scikit-learn | 3.3.2, 1.6.1 |
| **Database** | MongoDB | Latest |
| **Visualization** | Streamlit, Plotly | 1.44.1, 6.0.1 |
| **Infrastructure** | Docker | Latest |

---

## ğŸ“¦ Prerequisites

- **Python** 3.10 or higher
- **MongoDB** (local or containerized via Docker)
- **NewsAPI** API Key (https://newsapi.org)
- **macOS/Linux/Windows** with terminal access

### System Requirements
- Minimum 4GB RAM
- 2GB storage for MongoDB data
- Stable internet connection

---

## ğŸš€ Installation

### Step 1: Clone Repository
```bash
git clone <repository-url>
cd multilingual_drift_project
```

### Step 2: Create Virtual Environment
```bash
python3 -m venv drift_env310
source drift_env310/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Download NLTK Data
```bash
python -c "
import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
"
```

### Step 5: Setup MongoDB

**Option A: Local Installation**
```bash
brew tap mongodb/brew
brew install mongodb-community
brew services start mongodb-community
```

**Option B: Docker**
```bash
docker run -d -p 27017:27017 --name mongodb mongo:latest
```

---

## âš™ï¸ Configuration

### NewsAPI Configuration
1. Sign up at https://newsapi.org
2. Update API key in:
   - `scripts/newsapi_streaming.py` (line 6)
   - `scripts/real_time_ingestion.py` (line 20)

```python
API_KEY = "YOUR_NEWSAPI_KEY_HERE"
```

### LDA Model Parameters
In `scripts/lda_topic_modeling.py`:
```python
num_topics = 3          # Number of topics (3-5 recommended)
passes = 10             # Training passes
```

### Drift Detection Threshold
In `scripts/detect_topic_drift.py`:
```python
drift_threshold = 0.7   # Similarity < 0.7 = drift detected
```

---

## ğŸ“– Usage

### Complete Pipeline (Recommended)

**Terminal 1: Start MongoDB**
```bash
mongod --dbpath ~/mongodb-data/db
```

**Terminal 2: Start News Ingestion**
```bash
source drift_env310/bin/activate
python scripts/newsapi_streaming.py
```

**Terminal 3: Run Preprocessing (after 2-3 minutes)**
```bash
source drift_env310/bin/activate
python scripts/preprocess_text.py
```

**Terminal 4: Train LDA Model**
```bash
source drift_env310/bin/activate
python scripts/lda_topic_modeling.py
```

**Terminal 5: Detect Topic Drift**
```bash
source drift_env310/bin/activate
python scripts/detect_topic_drift.py
```

**Terminal 6: Launch Dashboard**
```bash
source drift_env310/bin/activate
streamlit run dashboard/streamlit_app.py
```

Access dashboard at `http://localhost:8501`

---

## ğŸ“ Project Structure

```
multilingual_drift_project/
â”œâ”€â”€ README.md                          # Project documentation
â”œâ”€â”€ requirements.txt                   # Dependencies
â”œâ”€â”€ scripts/                           # Core processing modules
â”‚   â”œâ”€â”€ newsapi_streaming.py          # Real-time ingestion
â”‚   â”œâ”€â”€ preprocess_text.py            # Text preprocessing
â”‚   â”œâ”€â”€ lda_topic_modeling.py         # Topic modeling
â”‚   â”œâ”€â”€ detect_topic_drift.py         # Drift detection
â”‚   â””â”€â”€ predict_topic_drift.py        # ML predictions
â””â”€â”€ dashboard/                         # Visualization
    â””â”€â”€ streamlit_app.py              # Interactive dashboard
```

---

## ğŸ”„ Data Flow Diagram

```
NewsAPI
   â†“
newsapi_streaming.py
   â†“ (Insert documents)
MongoDB: documents collection
   â†“ (Read articles)
preprocess_text.py
   â†“ (Update cleaned_tokens)
MongoDB: documents (updated)
   â†“ (Read preprocessed docs)
lda_topic_modeling.py
   â†“ (Extract topics per language)
MongoDB: topics collection
   â†“ (Read topics)
detect_topic_drift.py
   â†“ (Calculate similarity)
MongoDB: topic_drift_scores collection
   â†“ (Query all collections)
Streamlit Dashboard
   â†“
Interactive Visualizations (http://localhost:8501)
```

---

## ğŸ”Œ MongoDB Collections Schema

### documents Collection
```json
{
  "_id": ObjectId,
  "text": "Article text",
  "language": "en|hi|ta",
  "timestamp": ISODate,
  "cleaned_tokens": ["token1", "token2"]
}
```

### topics Collection
```json
{
  "_id": ObjectId,
  "topic_id": 0,
  "keywords": ["word1", "word2", "word3"]
}
```

### topic_drift_scores Collection
```json
{
  "_id": ObjectId,
  "topic_id_1": 0,
  "topic_id_2": 1,
  "similarity_score": 0.75,
  "drift_detected": true,
  "timestamp": ISODate
}
```

---

## ğŸ“Š Performance Metrics

| Metric | Expected Value |
|--------|---|
| News Ingestion Rate | 20 articles/30 sec |
| Preprocessing Time | 100 ms per document |
| LDA Training Time | 10-30 seconds (100+ docs) |
| Drift Detection Time | 50 ms per topic pair |
| Dashboard Load Time | <2 seconds |

---

## ğŸ› Troubleshooting

### MongoDB Connection Error
```bash
# Check if running
ps aux | grep mongod

# Start MongoDB
mongod --dbpath ~/mongodb-data/db

# Or Docker
docker run -d -p 27017:27017 --name mongodb mongo:latest
```

### NewsAPI Rate Limit
- Free tier: 100 requests/day
- Upgrade at https://newsapi.org/pricing
- Increase sleep interval in `newsapi_streaming.py`

### No Topics Generated
1. Run ingestion longer (5-10 minutes)
2. Check MongoDB for documents:
```bash
python -c "from pymongo import MongoClient; print(MongoClient()['topic_drift']['documents'].count_documents({}))"
```

### Streamlit Issues
```bash
streamlit cache clear
streamlit run dashboard/streamlit_app.py --logger.level=debug
```

---

## ğŸš€ Future Enhancements

1. **Real-time Alerts** - Email/Slack notifications
2. **Sentiment Analysis** - Alongside topic drift
3. **Better Models** - Top2Vec, BERTopic
4. **Scalability** - Kafka, Kubernetes
5. **UI Improvements** - WebSockets, exports
6. **More Languages** - Spanish, French, German
7. **MLOps** - Model versioning, A/B testing

---

## ğŸ“ Example Scenarios

### Scenario 1: News Trend Analysis
1. Run ingestion for 1 hour
2. Generate 5 topics
3. Observe similarity trends
4. Identify emerging vs. persistent topics

### Scenario 2: Multilingual Comparison
1. Collect news in English, Hindi, Tamil
2. Train separate models per language
3. Cross-reference keyword overlap
4. Identify global vs. localized topics

### Scenario 3: Anomaly Detection
1. Establish baseline drift scores
2. Monitor in real-time
3. Flag anomalies when similarity < threshold
4. Investigate root causes

---

## ğŸ”— References

- [Gensim LDA](https://radimrehurek.com/gensim/models/ldamodel.html)
- [NewsAPI](https://newsapi.org/docs)
- [MongoDB Python](https://pymongo.readthedocs.io/)
- [Streamlit](https://docs.streamlit.io/)
- [PySpark MLlib](https://spark.apache.org/docs/latest/ml-guide.html)
- [NLTK](https://www.nltk.org/)
- [SpaCy](https://spacy.io/)
